HAND DETECTION AND TRACKING


import cv2
import mediapipe as mp
import math
import time


class HandDetector:
    """
    Finds Hands using the mediapipe library. Exports the landmarks
    in pixel format. Adds extra functionalities like finding how
    many fingers are up or the distance between two fingers. Also
    provides bounding box info of the hand found.
    """

    def __init__(self, mode=False, maxHands=2, detectionCon=0.5, minTrackCon=0.5):
        """
        :param mode: In static mode, detection is done on each image: slower
        :param maxHands: Maximum number of hands to detect
        :param detectionCon: Minimum Detection Confidence Threshold
        :param minTrackCon: Minimum Tracking Confidence Threshold
        """
        self.mode = mode
        self.maxHands = maxHands
        self.detectionCon = detectionCon
        self.minTrackCon = minTrackCon

        self.mpHands = mp.solutions.hands
        self.hands = self.mpHands.Hands(static_image_mode=self.mode, max_num_hands=self.maxHands,
                                        min_detection_confidence=self.detectionCon,
                                        min_tracking_confidence=self.minTrackCon)
        self.mpDraw = mp.solutions.drawing_utils
        self.tipIds = [4, 8, 12, 16, 20]
        self.fingers = []
        self.lmList = []

    def findHands(self, img, draw=True, flipType=True):
        """
        Finds hands in a BGR image.
        :param img: Image to find the hands in.
        :param draw: Flag to draw the output on the image.
        :return: Image with or without drawings
        """
        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        self.results = self.hands.process(imgRGB)
        allHands = []
        h, w, c = img.shape
        if self.results.multi_hand_landmarks:
            for handType, handLms in zip(self.results.multi_handedness, self.results.multi_hand_landmarks):
                myHand = {}
                ## lmList
                mylmList = []
                xList = []
                yList = []
                for id, lm in enumerate(handLms.landmark):
                    px, py, pz = int(lm.x * w), int(lm.y * h), int(lm.z * w)
                    mylmList.append([px, py, pz])
                    xList.append(px)
                    yList.append(py)

                ## bbox
                xmin, xmax = min(xList), max(xList)
                ymin, ymax = min(yList), max(yList)
                boxW, boxH = xmax - xmin, ymax - ymin
                bbox = xmin, ymin, boxW, boxH
                cx, cy = bbox[0] + (bbox[2] // 2), \
                         bbox[1] + (bbox[3] // 2)

                myHand["lmList"] = mylmList
                myHand["bbox"] = bbox
                myHand["center"] = (cx, cy)

                if flipType:
                    if handType.classification[0].label == "Right":
                        myHand["type"] = "Left"
                    else:
                        myHand["type"] = "Right"
                else:
                    myHand["type"] = handType.classification[0].label
                allHands.append(myHand)

                ## draw
                if draw:
                    self.mpDraw.draw_landmarks(img, handLms,
                                               self.mpHands.HAND_CONNECTIONS)
                    cv2.rectangle(img, (bbox[0] - 20, bbox[1] - 20),
                                  (bbox[0] + bbox[2] + 20, bbox[1] + bbox[3] + 20),
                                  (255, 0, 255), 2)
                    cv2.putText(img, myHand["type"], (bbox[0] - 30, bbox[1] - 30), cv2.FONT_HERSHEY_PLAIN,
                                2, (255, 0, 255), 2)
        if draw:
            return allHands, img
        else:
            return allHands

    def fingersUp(self, myHand):
        """
        Finds how many fingers are open and returns in a list.
        Considers left and right hands separately
        :return: List of which fingers are up
        """
        myHandType = myHand["type"]
        myLmList = myHand["lmList"]
        if self.results.multi_hand_landmarks:
            fingers = []
            # Thumb
            if myHandType == "Right":
                if myLmList[self.tipIds[0]][0] > myLmList[self.tipIds[0] - 1][0]:
                    fingers.append(1)
                else:
                    fingers.append(0)
            else:
                if myLmList[self.tipIds[0]][0] < myLmList[self.tipIds[0] - 1][0]:
                    fingers.append(1)
                else:
                    fingers.append(0)

            # 4 Fingers
            for id in range(1, 5):
                if myLmList[self.tipIds[id]][1] < myLmList[self.tipIds[id] - 2][1]:
                    fingers.append(1)
                else:
                    fingers.append(0)
        return fingers

    def findDistance(self, p1, p2, img=None):
        """
        Find the distance between two landmarks based on their
        index numbers.
        :param p1: Point1
        :param p2: Point2
        :param img: Image to draw on.
        :param draw: Flag to draw the output on the image.
        :return: Distance between the points
                 Image with output drawn
                 Line information
        """

        x1, y1 = p1
        x2, y2 = p2
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
        length = math.hypot(x2 - x1, y2 - y1)
        info = (x1, y1, x2, y2, cx, cy)
        if img is not None:
            cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED)
            cv2.circle(img, (x2, y2), 15, (255, 0, 255), cv2.FILLED)
            cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), 3)
            cv2.circle(img, (cx, cy), 15, (255, 0, 255), cv2.FILLED)
            return length, info, img
        else:
            return length, info


def main():
    cap = cv2.VideoCapture(1)
    detector = HandDetector(detectionCon=0.8, maxHands=2)
    pTime=0
    cTime=0
    while True:
        # Get image frame
        success, img = cap.read()
        # Find the hand and its landmarks
        hands, img = detector.findHands(img)  # with draw
        # hands = detector.findHands(img, draw=False)  # without draw

        if hands:
            # Hand 1
            hand1 = hands[0]
            lmList1 = hand1["lmList"]  # List of 21 Landmark points
            bbox1 = hand1["bbox"]  # Bounding box info x,y,w,h
            centerPoint1 = hand1['center']  # center of the hand cx,cy
            handType1 = hand1["type"]  # Handtype Left or Right

            fingers1 = detector.fingersUp(hand1)

            if len(hands) == 2:
                # Hand 2
                hand2 = hands[1]
                lmList2 = hand2["lmList"]  # List of 21 Landmark points
                bbox2 = hand2["bbox"]  # Bounding box info x,y,w,h
                centerPoint2 = hand2['center']  # center of the hand cx,cy
                handType2 = hand2["type"]  # Hand Type "Left" or "Right"

                fingers2 = detector.fingersUp(hand2)

                # Find Distance between two Landmarks. Could be same hand or different hands
                length, info, img = detector.findDistance(lmList1[8][0:2], lmList2[8][0:2], img)  # with draw
                # length, info = detector.findDistance(lmList1[8], lmList2[8])  # with draw
        cTime = time.time()
        fps=1/(cTime-pTime)
        pTime=cTime
        cv2.putText(img,str(int(fps)),(10,70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)
        # Display
        cv2.imshow("Image", img)
        cv2.waitKey(1)


if __name__ == "__main__":
    main()

USING GESTURES TO CONTROL PRESENTATION

import cv2
import os
import numpy as np
from handtrackingmodule import HandDetector
import sys

#variables
width,height=int(1366/1.01),int(650) #dimensions of webcam
folderPath=sys.argv[1] #getting the folder path from command line
slideNumber=0
heightsmall,widthsmall=int(height/5),int(width/5) #dimensions of webcam on presentation
gestureThreshold=300
buttonPress=False
buttoncounter=0
buttondelay=10 #fps
annotations=[[]] #stores at points to draw at
annotationnumber=-1
annotationstart=False

#camera setup
cap=cv2.VideoCapture(1) # 0 for webcam, 4 for phone cam
cap.set(3,width)
cap.set(4,height)

#get list of prensentation images
#fix::10.png not working even if key=len
#maybe it is storing as string, convert it to integer
pathImages=sorted(os.listdir(folderPath),key=lambda x:(len(x),x)) #sorting according to numbers and length
print(pathImages)

#hand detector
detector=HandDetector(detectionCon=0.8,maxHands=1)

while True:
    success,img=cap.read()
    img=cv2.flip(img,1)
    #import images
    pathFullImage=os.path.join(folderPath,pathImages[slideNumber])
    currentSlide=cv2.imread(pathFullImage)
    currentSlide=cv2.resize(currentSlide,(width,height),interpolation=cv2.INTER_LINEAR)
    heigthCurrent,widthCurrent,_Current=currentSlide.shape


    hands,img=detector.findHands(img) #flipType=false will show the correctls hands, i.e left as left
    #drawing a line on the webcam so as to detect gestures only above that line
    cv2.line(img,(0,gestureThreshold),(width,gestureThreshold),(0,255,0),10)
    
    if hands and buttonPress is False:
        hand=hands[0] #get the first hand
        fingers=detector.fingersUp(hand)
        cx,cy=hand['center']
        #print(fingers )
        lmList=hand['lmList']

        #constrain values for easier drawing
        
        xVal=int(np.interp(lmList[8][0],[width//2,widthCurrent],[0,width]))
        yVal=int(np.interp(lmList[8][1],[150,height-150],[0,height]))
        indexFinger=xVal,yVal
        if cy<=gestureThreshold: #if hand is at the height of the face
            #Gesture-1 Go left
            if fingers == [1,0,0,0,0]: #thumb
                #print("left")
                
                if slideNumber>0:
                    buttonPress=True
                    slideNumber-=1
                    annotations=[[]] #stores at points to draw at
                    annotationnumber=-1
                    annotationstart=False
            
            #Gesture -2 Go right
            if fingers == [0,0,0,0,1]: #little finger
                #print("right")
                
                if slideNumber < len(pathImages)-1:
                    buttonPress=True
                    slideNumber+=1
                    annotations=[[]] #stores at points to draw at
                    annotationnumber=-1
                    annotationstart=False
            
        #Gesture -3 Show pointer
        if fingers == [0,1,1,0,0]: #index finger
            cv2.circle(currentSlide,indexFinger,8,(0,0,255),cv2.FILLED)

        #Gesture -4 Draw
        if fingers == [0,1,0,0,0]:
            if annotationstart == False:
                annotationstart = True
                annotationnumber+=1
                annotations.append([])
            cv2.circle(currentSlide,indexFinger,8,(0,0,200),cv2.FILLED)
            annotations[annotationnumber].append(indexFinger)
        else: 
            annotationstart=False
        
        #Gesture -5 Erase
        if fingers == [0,1,1,1,0]:
            if annotations:
                annotations.pop(-1)
                annotationnumber-=1
                buttonPress=True

    #Button pressed iterations
    if buttonPress:
        buttoncounter+=1
        if buttoncounter>buttondelay:
            buttoncounter=0
            buttonPress=False
    
    #draw at the points stored in annotations
    for i in range(len(annotations)):
        for j in range(len(annotations[i])):
            if j!=0:
                cv2.line(currentSlide,annotations[i][j-1],annotations[i][j],(200,0,0),6)
    
    #overlay of webcam on presentation
    imgSmall=cv2.resize(img,(widthsmall,heightsmall))
    currentSlide[0:heightsmall,widthCurrent-widthsmall:widthCurrent]=imgSmall
    
    cv2.imshow("Web Cam",img)
    cv2.imshow("Presentation",currentSlide)
    key=cv2.waitKey(1)
    if key==ord('q'):
        break

CUI USING BASH

#!/bin/bash


#gets the file name from the path
fullpath=$1
filename=$(basename ${fullpath})
#echo $filename
#output is filename.extension

#removing extension
xpath=${fullpath%/*}
xbase=${fullpath##*/}
# xfext=${xbase##*.} this stores the file extension
pptname=${xbase%.*} #this stores the filename without extension
#echo $pptname

#echo -n "Please enter ppt name"
#echo
#read pptname

if [ -d "$pptname/images"];
then 
	echo "Already present"
else	
    mkdir $pptname
    #copying the presentation from the input path to temporary folder
    cp  $1 $pptname
    cd $pptname
    mkdir images/
    echo "Converting presentation ..."
    unoconv $pptname.pptx $pptname.pdf
    echo "Doing final touches ..."
    cd images/
    convert ../$pptname.pdf i.png

#depreceated - converting images to numbers for listing in python
#as linux is not listing in numerical order

#num=1
#for file in *
#do cp $file ../../output/$num
#	num=$((num+1))
#done

#converting image names to only number for listing in python
#input each file in whatever order they are in
#removes the first two character i.e "i-"
#reverses it , i.e "10.png" wil be "gnp.01"
#removes the first 4 chars from the reversed string, output: 01"
#reverse it again to get the proper number, i.e: 01 will be 10"
    for file in *.png;
    do mv $file "$(echo $file | cut -c 3- | rev | cut -c 5- | rev)"
    done
  fi
    cd ../..
    echo "Thank you for your patience"
    echo "Loading presentation"


#ls
#echo $pptname
python3 main.py $pptname/images/
